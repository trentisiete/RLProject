# configs/agent_config.yaml

agent:
  # Which agent class to use: dqn, ppo, random
  type: dqn
  network: "MlpQNetwork" # podria ser CNN_atari (Like different Brains)
  train_frequency: 4

  # All hyperparameters that your agentâ€™s constructor
  # and update() routine will consume
  hyperparams:
    # Common DQN params
    lr: 0.001                 # learning rate
    gamma: 0.99                # discount factor
    batch_size: 32             # minibatch size
    replay_buffer_size: 10000 # max transitions to store
    min_replay_buffer_size: 1000
    target_update_freq: 200   # how often (in steps) to sync target net


    # Exploration schedule
    epsilon_start: 1.0
    epsilon_end: 0.05
    epsilon_decay_steps: 20000

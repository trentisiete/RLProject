{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4ed8879",
   "metadata": {},
   "source": [
    "# CartPole-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c426e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Imports\n",
    "from src.utils.config import load_configs, make_env, make_agent\n",
    "from src.train import ExperimentRunner, ExperimentResult\n",
    "from src.agents.dqn import DQNAgent\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from src.evaluate import watch_agent\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ec87c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Añade la ruta del proyecto (ajusta si tu notebook está en otra carpeta)\n",
    "sys.path.append(str(Path().resolve().parent / \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d47b644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Create the environment\n",
    "#    – render_mode='rgb_array' lets you grab frames (e.g. for plotting later)\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f2b791",
   "metadata": {},
   "source": [
    "#### Action and State Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8cc655e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: Box([-4.8               -inf -0.41887903        -inf], [4.8               inf 0.41887903        inf], (4,), float32)\n",
      "Action space: Discrete(2)\n",
      "Space shape:  (4,)\n",
      "Action shape:  Discrete(2)\n"
     ]
    }
   ],
   "source": [
    "# 3) Inspect spaces\n",
    "print(\"Observation space:\", env.observation_space)  # Box(4,)\n",
    "print(\"Action space:\", env.action_space)            # Discrete(2)\n",
    "\n",
    "print('Space shape: ', env.observation_space.shape)\n",
    "print('Action shape: ', env.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a980aa",
   "metadata": {},
   "source": [
    "#### Running an Episode of CartPole-V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "416a35ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\miniconda3\\envs\\dqn-env\\lib\\site-packages\\pygame\\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 600, 3)\n",
      "Step 00 – obs=[ 0.03 -0.2   0.04  0.32], reward=1.0, done=False\n",
      "(400, 600, 3)\n",
      "Step 01 – obs=[ 0.02 -0.4   0.04  0.63], reward=1.0, done=False\n",
      "(400, 600, 3)\n",
      "Step 02 – obs=[ 0.02 -0.2   0.06  0.35], reward=1.0, done=False\n",
      "(400, 600, 3)\n",
      "Step 03 – obs=[ 0.01 -0.01  0.06  0.07], reward=1.0, done=False\n",
      "(400, 600, 3)\n",
      "Step 04 – obs=[ 0.01 -0.2   0.06  0.39], reward=1.0, done=False\n",
      "(400, 600, 3)\n",
      "Step 05 – obs=[ 0.01 -0.4   0.07  0.7 ], reward=1.0, done=False\n",
      "(400, 600, 3)\n",
      "Step 06 – obs=[-0.   -0.21  0.09  0.43], reward=1.0, done=False\n",
      "(400, 600, 3)\n",
      "Step 07 – obs=[-0.01 -0.01  0.09  0.16], reward=1.0, done=False\n",
      "(400, 600, 3)\n",
      "Step 08 – obs=[-0.01 -0.21  0.1   0.48], reward=1.0, done=False\n",
      "(400, 600, 3)\n",
      "Step 09 – obs=[-0.01 -0.02  0.11  0.22], reward=1.0, done=False\n"
     ]
    }
   ],
   "source": [
    "# 4) Reset and take a few random steps\n",
    "obs, info = env.reset(seed=42)\n",
    "frames = []\n",
    "for step in range(10):\n",
    "    action = env.action_space.sample()              # random action: 0 or 1\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    frame  = env.render()\n",
    "    print(frame.shape)\n",
    "    frames.append(env.render())\n",
    "    print(f\"Step {step:02d} – obs={obs.round(2)}, reward={reward}, done={done}\")\n",
    "    if done:\n",
    "        obs, info = env.reset() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "721c68aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Close when done\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8557c265",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_np = np.stack(frames)  # Shape: (num_frames, alto, ancho, 3)\n",
    "frames_tensor = torch.from_numpy(frames_np)  # Tensor de shape igual\n",
    "\n",
    "# Si quieres que el canal de color sea la segunda dimensión (formato PyTorch: N, C, H, W):\n",
    "frames_tensor = frames_tensor.permute(0, 3, 1, 2)  # (num_frames, 3, alto, ancho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e518c4",
   "metadata": {},
   "source": [
    "#### Training model with Experiment Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c50eec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CartPole-v1 (Seed 100): 100%|██████████| 15000/15000 [28:58<00:00,  8.63it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model state to results/dqn_cartpole/final_model.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "config_dir = Path(\"../configs/\")\n",
    "cfg = load_configs(config_dir)\n",
    "runner = ExperimentRunner(cfg)\n",
    "all_results = runner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48d772b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watching agent from results/dqn_cartpole/final_model.pth\n",
      "Episode 1: Total Reward  =79.0\n",
      "Episode 2: Total Reward  =14.0\n",
      "Episode 3: Total Reward  =45.0\n",
      "Episode 4: Total Reward  =15.0\n",
      "Episode 5: Total Reward  =12.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"../configs/evaluate_config.yaml\", 'r') as f:\n",
    "        eval_config = yaml.safe_load(f)\n",
    "\n",
    "watch_agent(eval_config, cfg['agent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48cec656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'gamma': 0.99, 'batch_size': 16, 'replay_buffer_size': 10000, 'min_replay_buffer_size': 1000, 'target_update_freq': 200, 'epsilon_start': 1.0, 'epsilon_end': 0.05, 'epsilon_decay_steps': 20000}\n"
     ]
    }
   ],
   "source": [
    "print(cfg['agent']['hyperparams'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cb43fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8afaadf1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dqn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
